{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:22:01.341707Z",
     "start_time": "2019-10-14T23:22:01.271092Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#regex imports\n",
    "import re\n",
    "import string\n",
    "\n",
    "#graph imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#scraping imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "\n",
    "#NLP imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "#Cluster analysis imports\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get URLs for XML files on Bundestag website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:22:06.518481Z",
     "start_time": "2019-10-14T23:22:01.350500Z"
    }
   },
   "outputs": [],
   "source": [
    "# run Chrome with Selenium\n",
    "chromedriver = \"/Applications/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "url = \"https://www.bundestag.de/services/opendata\"\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:22:06.575743Z",
     "start_time": "2019-10-14T23:22:06.524368Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_to_link_list ():\n",
    "    '''finds all XML links and adds them to a list'''\n",
    "    soup_links = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    regex = re.compile('.*XML .*')\n",
    "    documents = soup_links.find_all(title=regex)\n",
    "    \n",
    "    for i in documents:\n",
    "        link_list.append(i['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:22:51.607982Z",
     "start_time": "2019-10-14T23:22:06.602252Z"
    }
   },
   "outputs": [],
   "source": [
    "#click through all pages on Bundestag website with parliament transcripts for current term of office \n",
    "link_list = []\n",
    "\n",
    "for i in range(21):\n",
    "    button = driver.find_element_by_xpath(\"//button[@type='button'][@class='slick-next slick-arrow']\")\n",
    "    button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "add_to_link_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:22:51.613801Z",
     "start_time": "2019-10-14T23:22:51.610430Z"
    }
   },
   "outputs": [],
   "source": [
    "#create list with complete URLs\n",
    "\n",
    "url_list = []\n",
    "url_start = 'https://www.bundestag.de'\n",
    "\n",
    "for i in link_list:\n",
    "    url_list.append(url_start + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scraping and parsing of XML files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:22:51.651435Z",
     "start_time": "2019-10-14T23:22:51.616280Z"
    }
   },
   "outputs": [],
   "source": [
    "# create empty dictionary for data scraping\n",
    "keys = ['speech_ID','date','speaker_ID','first_name','last_name','party','speech','comments']\n",
    "data_dict = {}\n",
    "\n",
    "for i in keys:\n",
    "    data_dict[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.133633Z",
     "start_time": "2019-10-14T23:22:51.655225Z"
    }
   },
   "outputs": [],
   "source": [
    "#run scraping and parsing\n",
    "\n",
    "fail_list = []\n",
    "\n",
    "for url_ in url_list:\n",
    "    try:\n",
    "        url = url_\n",
    "        user_agent = {'User-Agent' : 'Mozilla/5.0'}\n",
    "\n",
    "        response = requests.get(url, headers=user_agent)\n",
    "        \n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        \n",
    "        speeches = soup.find_all('rede')\n",
    "        \n",
    "        for i in speeches:\n",
    "    \n",
    "            #ID speech\n",
    "            speech_ID = i['id']\n",
    "        \n",
    "            #date\n",
    "            date = soup.find('datum').attrs['date']\n",
    "\n",
    "            #ID speaker\n",
    "            speaker_ID = i.find(klasse='redner').find('redner').attrs['id']\n",
    "\n",
    "            #first name\n",
    "            first_name = i.find(klasse='redner').find('redner').find('vorname').text\n",
    "\n",
    "            #last name\n",
    "            last_name = i.find(klasse='redner').find('redner').find('nachname').text\n",
    "\n",
    "            #party/ role\n",
    "            try:\n",
    "                party = i.find(klasse='redner').find('redner').find('rolle_lang').text\n",
    "            except:\n",
    "                party = i.find(klasse='redner').find('redner').find('fraktion').text\n",
    "\n",
    "            #speech, exclude first item in list as it is ID, name etc.\n",
    "            speech_list = i.find_all('p')[1:]\n",
    "            speech = ''\n",
    "            for j in speech_list:\n",
    "                speech += j.text\n",
    "\n",
    "            #comments\n",
    "            comments = []\n",
    "            comments_list = i.find_all('kommentar')\n",
    "            for i in comments_list:\n",
    "                comments.append(i.text)\n",
    "\n",
    "            #populate dictionary\n",
    "            for i in keys:\n",
    "                data_dict[i].append(eval(i))\n",
    "    except:\n",
    "        fail_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.178142Z",
     "start_time": "2019-10-14T23:23:59.137448Z"
    }
   },
   "outputs": [],
   "source": [
    "#create dataframe\n",
    "df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T03:09:36.264809Z",
     "start_time": "2019-09-24T03:09:36.261018Z"
    }
   },
   "source": [
    "# 4. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Clean information on parliament member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T03:44:50.177767Z",
     "start_time": "2019-09-24T03:44:50.174576Z"
    }
   },
   "source": [
    "### 4.1.a Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.193661Z",
     "start_time": "2019-10-14T23:23:59.182234Z"
    }
   },
   "outputs": [],
   "source": [
    "#add full name column\n",
    "df['full_name'] = df['last_name'] + ', ' + df['first_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.211336Z",
     "start_time": "2019-10-14T23:23:59.198336Z"
    }
   },
   "outputs": [],
   "source": [
    "#lists with parliament roles\n",
    "\n",
    "CDU_secretaries = (['Merkel, Angela','Scheuer, Andreas','Klöckner, Julia','Altmaier, Peter','Karliczek, Anja',\n",
    "                    'Spahn, Jens','Seehofer, Horst','Müller, Gerd','Leyen, Ursula','Kramp-Karrenbauer, Annegret'])\n",
    "\n",
    "SPD_secretaries = (['Schulze, Svenja','Heil, Hubertus','Giffey, Franziska','Barley, Katarina','Lambrecht, Christine',\n",
    "                    'Scholz, Olaf','Maas, Heiko'])\n",
    "\n",
    "\n",
    "CDU_undersecretaries = (['Barthle, Norbert','Bär, Dorothee','Braun, Helge', 'Bareiß, Thomas','Bilger, Steffen',\n",
    "                         'Ferlemann, Enak','Flachsbarth, Maria','Fuchtel, Hans-Joachim', 'Gebhart, Thomas',\n",
    "                         'Grütters, Monika','Hirte, Christian','Hoppenstedt, Hendrik','Krings, Günter',\n",
    "                         'Mayer, Stephan','Meister, Michael','Rachel, Thomas','Stübgen, Michael','Tauber, Peter',\n",
    "                         'Wanderwitz, Marco','Weiss, Sabine','Widmann-Mauz, Annette','Wittke, Oliver'])\n",
    "\n",
    "SPD_undersecretaries = (['Annen, Niels','Hagedorn, Bettina','Hagl-Kehl, Rita','Griese, Kerstin','Kramme, Anette',\n",
    "                         'Lange, Christian','Lambrecht, Christine','Marks, Caren','Müntefering, Michelle',\n",
    "                         'Pronold, Florian','Roth, Michael','Ryglewski, Sarah','Schwarzelühr-Sutter, Rita',\n",
    "                         'Silberhorn, Thomas'])\n",
    "\n",
    "CDU_other_roles = ['Brauksiepe, Ralf','Spahn, Jens','Schäuble, Dr. Wolfgang','Karliczek, Anja']\n",
    "\n",
    "independent_members = (['Bülow, Marco', 'Mieruch, Mario', 'Petry, Frauke','Kamann, Uwe'])\n",
    "\n",
    "secretary_list = CDU_secretaries + SPD_secretaries\n",
    "\n",
    "undersecretary_list = CDU_undersecretaries + SPD_undersecretaries\n",
    "\n",
    "cabinet_list = secretary_list + undersecretary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.220860Z",
     "start_time": "2019-10-14T23:23:59.215368Z"
    }
   },
   "outputs": [],
   "source": [
    "#create party dictionary\n",
    "party_dict = {'CDU/CSU': 'CDU/CSU','AfD': 'AfD', 'SPD': 'SPD','FDP': 'FDP','DIE LINKE':'DIE LINKE',\n",
    "               'BÜNDNIS 90/DIE GRÜNEN':'BÜNDNIS 90/DIE GRÜNEN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.231782Z",
     "start_time": "2019-10-14T23:23:59.222914Z"
    }
   },
   "outputs": [],
   "source": [
    "#dictionary with resorts\n",
    "\n",
    "resort_dict = ({'Merkel, Angela':'Bundeskanzlerin','Scholz, Olaf':'Finanzen','Seehofer, Horst':'Inneres, Bau und Heimat',\n",
    "                'Maas, Heiko':'Auswärtiges','Altmaier, Peter':'Wirtschaft und Energie','Barley, Katarina':'Justiz und Verbraucherschutz',\n",
    "                'Lambrecht, Christine':'Justiz und Verbraucherschutz/ Finanzen','Heil, Hubertus':'Arbeit und Soziales',\n",
    "                'Leyen, Ursula':'Verteidigung','Kramp-Karrenbauer, Annegret':'Verteidigung','Klöckner, Julia':'Ernährung und Landwirtschaft',\n",
    "                'Giffey, Franziska':'Familie, Senioren, Frauen und Jugend','Spahn, Jens':'Gesundheit',\n",
    "                'Scheuer, Andreas':'Verkehr und digitale Infrastruktur', 'Schulze, Svenja':'Umwelt, Naturschutz und nukleare Sicherheit',\n",
    "                'Karliczek, Anja':'Bildung und Forschung','Müller, Gerd':'Wirtschaftliche Zusammenarbeit und Entwicklung',\n",
    "                'Braun, Helge':'Bundeskanzleramt',\n",
    "                'Grütters, Monika':'Kultur und Medien','Hoppenstedt, Hendrik':'Bürokratieabbau und bessere Rechtsetzung, Bund-Länder-Beziehungen',\n",
    "                'Widmann-Mauz, Annette':'Migration, Flüchtlinge und Integration','Bär, Dorothee':'Digitalisierung',\n",
    "                'Hagedorn, Bettina':'Finanzen','Ryglewski Sarah':'Finanzen','Krings, Günter':'Inneres, Bau und Heimat',\n",
    "                'Wanderwitz, Marco':'Inneres, Bau und Heimat','Mayer, Stephan':'Inneres, Bau und Heimat',\n",
    "                'Annen, Niels':'Auswärtiges','Müntefering, Michelle':'Auswärtiges - Internationale Kulturpolitik',\n",
    "                'Roth, Michael':'Auswärtiges - Europa, Deutsch-französische Zusammenarbeit',\n",
    "                'Bareiß, Thomas':'Wirtschaft und Energie - Tourismus','Hirte, Christian':'Wirtschaft und Energie - Neue Bundesländer',\n",
    "                'Wittke, Oliver':'Wirtschaft und Energie - EITI','Hagl-Kehl, Rita':'Justiz und Verbraucherschutz',\n",
    "                'Lange, Christian':'Justiz und Verbraucherschutz','Griese, Kerstin':'Arbeit und Soziales',\n",
    "                'Kramme, Anette':'Arbeit und Soziales','Tauber, Peter':'Verteidigung','Silberhorn, Thomas':'Verteidigung',\n",
    "                'Fuchtel, Hans-Joachim':'Ernährung und Landwirtschaft','Stübgen, Michael':'Ernährung und Landwirtschaft',\n",
    "                'Marks, Caren':'Familie, Senioren, Frauen und Jugend','Zierke, Stefan':'Familie, Senioren, Frauen und Jugend',\n",
    "                'Gebhart, Thomas':'Gesundheit','Weiss, Sabine':'Gesundheit','Bilger, Steffen':'Verkehr und digitale Infrastruktur',\n",
    "                'Ferlemann, Enak':'Verkehr und digitale Infrastruktur','Pronold, Florian':'Umwelt, Naturschutz und nukleare Sicherheit',\n",
    "                'Schwarzelühr-Sutter, Rita':'Umwelt, Naturschutz und nukleare Sicherheit','Meister, Michael':'Bildung und Forschung',\n",
    "                'Rachel, Thomas':'Bildung und Forschung','Barthle, Norbert':'Wirtschaftliche Zusammenarbeit und Entwicklung',\n",
    "                'Flachsbarth, Maria':'Wirtschaftliche Zusammenarbeit und Entwicklung'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.237753Z",
     "start_time": "2019-10-14T23:23:59.233860Z"
    }
   },
   "outputs": [],
   "source": [
    "#dictionary with duplicate names\n",
    "duplicates_dict = ({'Bluhm, Heidrun':'Bluhm-Förster, Heidrun','Cotar, Joana Eleonora':'Cotar, Joana',\n",
    "                    'Gauland, Alexander':'Gauland, Eberhardt Alexander',\n",
    "                    'Elsner von Gronow, Berengar':'Gronow, Berengar Elsner von',\n",
    "                    'Kuhle, Konstantin':'Kuhle, Konstantin Elias',\n",
    "                    'Schreiber, Eva-Maria':'Schreiber, Eva-Maria Elisabeth','Weiler, Albert':'Weiler, Albert H.'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.b Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.247331Z",
     "start_time": "2019-10-14T23:23:59.239618Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_party_1(row):\n",
    "    '''adjusts party for parliament members with official positions or without party membership'''\n",
    "    \n",
    "    #CDU/CSU\n",
    "    if row['full_name'] in CDU_secretaries:\n",
    "        return 'CDU/CSU'\n",
    "    elif row['full_name'] in CDU_undersecretaries:\n",
    "        return 'CDU/CSU'\n",
    "    elif row['full_name'] in CDU_other_roles:\n",
    "        return 'CDU/CSU'\n",
    "    \n",
    "    #SPD\n",
    "    elif row['full_name']  in SPD_secretaries:\n",
    "        return 'SPD'    \n",
    "    elif row['full_name']  in SPD_undersecretaries:\n",
    "        return 'SPD'\n",
    "    \n",
    "    #independent\n",
    "    elif row['full_name']  in independent_members:\n",
    "        return 'Fraktionslos'\n",
    "    \n",
    "    #all other\n",
    "    else:\n",
    "        return row['party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.259018Z",
     "start_time": "2019-10-14T23:23:59.251063Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_party_2(string):\n",
    "    '''identifies guest speakers who are not parliament members as other'''\n",
    "    try:\n",
    "        party = party_dict[string]\n",
    "    except:\n",
    "        party = 'Other'\n",
    "    return party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.267833Z",
     "start_time": "2019-10-14T23:23:59.263076Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cabinet(name):\n",
    "    '''get role in parliament'''\n",
    "    \n",
    "    if name in cabinet_list:\n",
    "        return 'Minister'\n",
    "    elif name in secretary_list:\n",
    "        return 'Staatssekretär/-minister'\n",
    "    else:\n",
    "        return 'Parlament'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.274535Z",
     "start_time": "2019-10-14T23:23:59.270639Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_resort(name):\n",
    "    '''add resort information'''\n",
    "    \n",
    "    if name in list(resort_dict.keys()):\n",
    "        return resort_dict[name]\n",
    "    else:\n",
    "        return 'n/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.279973Z",
     "start_time": "2019-10-14T23:23:59.276545Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_duplicates(string):\n",
    "    '''adjusts duplicate names'''\n",
    "    if string in list(duplicates_dict.keys()):\n",
    "        return duplicates_dict[string]\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T03:49:56.528107Z",
     "start_time": "2019-09-24T03:49:56.524173Z"
    }
   },
   "source": [
    "### 4.1.c Apply functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:23:59.973493Z",
     "start_time": "2019-10-14T23:23:59.282226Z"
    }
   },
   "outputs": [],
   "source": [
    "df['party'] = df.apply(get_party_1, axis=1)\n",
    "df['party'] = df['party'].apply(get_party_2)\n",
    "df['cabinet'] = df['full_name'].apply(get_cabinet)\n",
    "df['resort'] = df['full_name'].apply(get_resort)\n",
    "df['full_name'] = df['full_name'].apply(adjust_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Clean speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:24:10.022186Z",
     "start_time": "2019-10-14T23:23:59.975728Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create baseline \n",
    "df['speech_clean'] = df['speech']\n",
    "\n",
    "#Remove numbers\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "df['speech_clean'] = df['speech_clean'].apply(alphanumeric)\n",
    "\n",
    "#Remove punctuation\n",
    "punctuation = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "df['speech_clean'] = df['speech_clean'].apply(punctuation)\n",
    "\n",
    "#Remove non-breaking space\n",
    "xa0 = lambda x: re.sub('\\xa0', ' ', x)\n",
    "xad = lambda x: re.sub('\\xad', ' ', x)\n",
    "df['speech_clean'] = df['speech_clean'].apply(xa0).apply(xad)\n",
    "\n",
    "#Remove dash\n",
    "dash = lambda x: re.sub('–', ' ', x)\n",
    "df['speech_clean'] = df['speech_clean'].apply(dash)\n",
    "\n",
    "#Make lower case\n",
    "lower = lambda x: x.lower()\n",
    "df['speech_clean'] = df['speech_clean'].apply(lower)\n",
    "\n",
    "#Replace hyphens\n",
    "hyphen_1 = lambda x: re.sub('“', ' ', x)\n",
    "hyphen_2 = lambda x: re.sub('„', ' ', x)\n",
    "df['speech_clean'] = df['speech_clean'].apply(hyphen_1).apply(hyphen_2)\n",
    "\n",
    "#Remove doubles space\n",
    "spaces = lambda x: ' '.join(x.split())\n",
    "df['speech_clean'] = df['speech_clean'].apply(spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Remove speeches with less than 50 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:24:10.027754Z",
     "start_time": "2019-10-14T23:24:10.024586Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_count(string):\n",
    "    '''counts number of words in speech'''\n",
    "    count = len(string.split())\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:24:10.545501Z",
     "start_time": "2019-10-14T23:24:10.030162Z"
    }
   },
   "outputs": [],
   "source": [
    "df['word_count'] = df['speech_clean'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:24:10.580379Z",
     "start_time": "2019-10-14T23:24:10.549838Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['word_count']>49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Word tokenization and vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:08:28.637011Z",
     "start_time": "2019-09-24T04:08:28.633822Z"
    }
   },
   "source": [
    "## 5.1. Tokenization and vectorization preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:24:10.593150Z",
     "start_time": "2019-10-14T23:24:10.583873Z"
    }
   },
   "outputs": [],
   "source": [
    "#load stopwords\n",
    "stop_words = stopwords.words('german')\n",
    "\n",
    "# add manual stopwords\n",
    "manual_stop_words = (['werd','herr','kolleg','mehr','woll','wer', 'gut', 'wichtig','uber','konn','sag','frag', 'sag',\n",
    "                      'frau', 'herr''schon', 'wurd', 'gibt', 'thema', 'ganz', 'mal', 'konn', 'glaub', 'gesagt', 'mach',\n",
    "                      'geht', 'stell', 'all', 'and', 'red', 'hatt', 'debatt','mocht', 'dank', 'word', 'lieb', 'letzt',\n",
    "                      'find', 'darub', 'darauf', 'desweg','eigent', 'vielleicht', 'genau', 'gar','bundesregier','deutsch'])\n",
    "\n",
    "stop_words = stop_words + manual_stop_words\n",
    "\n",
    "#load stemmer\n",
    "stemmer = SnowballStemmer('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:24:10.600444Z",
     "start_time": "2019-10-14T23:24:10.595320Z"
    }
   },
   "outputs": [],
   "source": [
    "#create tokenizer and stemmer function\n",
    "def tokenize_and_stem(text):\n",
    "    '''applies tokenization and stemming'''\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        token = stemmer.stem(token)\n",
    "        if len(token) > 2:\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:08:51.400888Z",
     "start_time": "2019-09-24T04:08:51.396171Z"
    }
   },
   "source": [
    "## 5.2. Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:25:56.921294Z",
     "start_time": "2019-10-14T23:24:10.602740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['bundesregi', 'dasselb', 'demselb', 'denselb', 'derselb', 'dess', 'desselb', 'dieselb', 'eur', 'fur', 'geg', 'gewes', 'hint', 'ind', 'jed', 'jen', 'konnt', 'manch', 'musst', 'ohn', 'selb', 'solch', 'sollt', 'sond', 'unt', 'wahrend', 'weit', 'welch', 'wied', 'wollt', 'zwisch'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=stop_words,tokenizer=tokenize_and_stem,max_df=0.9)\n",
    "sparse_tfidf = tfidf.fit_transform(df['speech_clean'])\n",
    "tfidf_feature_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:10:53.805406Z",
     "start_time": "2019-09-24T04:10:53.799757Z"
    }
   },
   "source": [
    "# 6. Topic modeling - NMF (35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:11:15.914393Z",
     "start_time": "2019-09-24T04:11:15.911021Z"
    }
   },
   "source": [
    "## 6.1. Topic modeling preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:25:56.932581Z",
     "start_time": "2019-10-14T23:25:56.924310Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    '''shows topics identified in topic modeling'''\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:14:30.046741Z",
     "start_time": "2019-09-24T04:14:30.042296Z"
    }
   },
   "source": [
    "## 6.2. Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:34.610790Z",
     "start_time": "2019-10-14T23:25:56.936681Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf_35 = NMF(35,random_state=1)\n",
    "nmf_35_topic = nmf_35.fit_transform(sparse_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Topic identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:34.621687Z",
     "start_time": "2019-10-14T23:27:34.612880Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_names = (['Füllwörter','Europa/EU-Politik','Bundeswehr','Haushalt','Familienpolitik','Parlamentsabstimmung',\n",
    "                   'Gesetzgebung','Bildungspolitik','Arbeitsmarkt','Miete/Wohnen','Umwelt/Energie','Sudaneinsatz',\n",
    "                   'NATO/Sicherheitspolitik','Pflegepolitik','Studium','Parlamentsdebatten','Organspende',\n",
    "                   'Automobilverkehr','Ländlicher Raum','Wirtschaft','Förderalismus','Grundgesetz/Demokratie',\n",
    "                   'Syrienkonflikt/Naher Osten','Kosovoeinsatz','Nahostkonflikt','Innenpolitik/Rechtstaat',\n",
    "                   'Flüchtlingspolitik','Seenotrettung','Gesundheitspolitik','Afghanistaneinsatz','Brexit',\n",
    "                   'Digitaliserung','Finanzmarktpolitik','Malieinsatz','Landwirtschaft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:34.847046Z",
     "start_time": "2019-10-14T23:27:34.627121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: ' Füllwörter '\n",
      "haushalt, geld, minist, bereich, investition, neu, mittel, koalition, zukunft, jahr, gross, schon, einzelplan, dafur, richtig, scholz, projekt, etat, beim, aufgab\n",
      "\n",
      "Topic: ' Europa/EU-Politik '\n",
      "europa, union, gemeinsam, national, europas, mitgliedstaat, stark, brauch, deutschland, kommission, bank, staat, eben, interess, zukunft, sozial, aussenpolit, zusammenarbeit, fried, griechenland\n",
      "\n",
      "Topic: ' Bundeswehr '\n",
      "gesetzentwurf, gesetz, regel, verfahr, moglich, richtlini, berat, weit, schon, vorlieg, bundesverfassungsgericht, fall, anhor, entwurf, punkt, entsprech, betroff, erst, heut, jahr\n",
      "\n",
      "Topic: ' Haushalt '\n",
      "einsatz, mandat, mali, soldat, mission, afghanistan, soldatinn, irak, malisch, region, operation, guardian, sea, kosovo, militar, mittelme, ausbild, atalanta, engagement, minusma\n",
      "\n",
      "Topic: ' Familienpolitik '\n",
      "kind, famili, elt, kinderzuschlag, kindergeld, kinderarmut, familienpolit, alleinerzieh, leb, leistung, armut, gesellschaft, mutt, gesetz, jugend, elterngeld, kita, stark, erzieh, teilhabepaket\n",
      "\n",
      "Topic: ' Parlamentsabstimmung '\n",
      "beschlussempfehl, stimmt, drucksach, enthalt, abstimm, fraktion, stimm, ausschuss, dageg, angenomm, grun, link, bundnis, uberweisungsvorschlag, entschliessungsantrag, empfiehlt, afd, fdp, federfuhr, cdu\n",
      "\n",
      "Topic: ' Gesetzgebung '\n",
      "pfleg, pflegebedurft, pflegekraft, pflegeversicher, krankenhaus, altenpfleg, angehor, mensch, ambulant, pflegend, finanzier, arbeitsbeding, bess, bereich, bezahl, pflegepersonal, schritt, pflegeberuf, spahn, brauch\n",
      "\n",
      "Topic: ' Bildungspolitik '\n",
      "land, bund, kommun, schul, bundesland, gemeinsam, wohnungsbau, verantwort, sozial, grundgesetz, grundgesetzander, aufgab, dafur, digitalpakt, stadt, gemeind, deshalb, grundsteu, zustand, kommunal\n",
      "\n",
      "Topic: ' Arbeitsmarkt '\n",
      "mensch, arbeitsmarkt, arbeit, sozial, arbeitslos, langzeitarbeitslos, beschaftigt, hartz, behinder, jobcent, gesellschaft, chanc, leb, teilhab, sozialstaat, beschaft, weiterbild, mindestlohn, arbeitgeb, arbeitnehm\n",
      "\n",
      "Topic: ' Miete/Wohnen '\n",
      "miet, wohnung, mietpreisbrems, wohnraum, bezahlbar, mieterinn, bau, vermiet, sozial, wohn, wohnungsbau, wohnungsmarkt, stadt, mietrecht, quadratmet, mensch, baukindergeld, modernisier, berlin, wohngeld\n",
      "\n",
      "Topic: ' Umwelt/Energie '\n",
      "klimaschutz, erneuerbar, energi, energiew, ziel, preis, erreich, emissionshandel, strom, prozent, brauch, klimawandel, massnahm, eeg, klimaziel, kohleausstieg, kohl, emission, ausbau, deutschland\n",
      "\n",
      "Topic: ' Sudaneinsatz '\n",
      "menschenrecht, mensch, humanitar, international, weltweit, welt, religionsfrei, hilf, afrika, religion, deutschland, global, christ, entwicklungszusammenarbeit, migration, land, nation, vereint, million, muslim\n",
      "\n",
      "Topic: ' NATO/Sicherheitspolitik '\n",
      "russland, vertrag, nato, inf, nuklear, usa, russisch, abrust, amerikan, atomwaff, welt, trump, mittelstreckenraket, international, abkomm, sicherheitspolit, neu, iran, china, russ\n",
      "\n",
      "Topic: ' Pflegepolitik '\n",
      "bundeswehr, soldat, soldatinn, nato, trupp, wehrbeauftragt, ministerin, dien, einsatz, streitkraft, ley, ausrust, einsatzbereitschaft, material, trendwend, arme, jahr, militar, auslandseinsatz, verteid\n",
      "\n",
      "Topic: ' Studium '\n",
      "bildung, beruf, ausbild, schul, forschung, jung, akadem, hochschul, dual, wissenschaft, auszubild, karliczek, ministerin, weiterbild, digitalpakt, betrieb, studium, berufsbild, bereich, jugend\n",
      "\n",
      "Topic: ' Parlamentsdebatten '\n",
      "antrag, fdp, schon, afd, link, grun, fraktion, ausschuss, punkt, forder, vorschlag, ford, kolleginn, sollt, bundestag, namlich, wort, uberweis, richtig, natur\n",
      "\n",
      "Topic: ' Organspende '\n",
      "organsp, widerspruchslos, spend, organ, entscheid, mensch, angehor, spenderorgan, krankenhaus, tod, entscheidungslos, transplantationsbeauftragt, jed, potenziell, organentnahm, selbstbestimmungsrecht, vertrau, freiwill, ethisch, leb\n",
      "\n",
      "Topic: ' Automobilverkehr '\n",
      "landlich, raum, region, kultur, lebensverhaltnis, stadt, gleichwert, ehrenamt, mensch, ort, entwickl, brauch, kulturell, infrastruktur, stark, leb, strukturschwach, forder, landwirtschaft, programm\n",
      "\n",
      "Topic: ' Ländlicher Raum '\n",
      "landwirtschaft, landwirt, ernahr, ministerin, betrieb, bau, tier, verbrauch, glyphosat, klockn, gesund, wald, agrarpolit, bundesministerin, alternativ, tierwohl, lebensmittel, staatssekretar, nachhalt, tierschutz\n",
      "\n",
      "Topic: ' Wirtschaft '\n",
      "unternehm, mittelstand, steu, wirtschaft, deutschland, klein, forschungsforder, prozent, start, innovation, bank, forschung, ups, investition, mittl, altmai, betrieb, gross, wettbewerb, arbeitnehm\n",
      "\n",
      "Topic: ' Förderalismus '\n",
      "brexit, grossbritanni, britisch, brit, austritt, konigreich, union, vereinigt, abkomm, austrittsabkomm, burg, london, hart, nordirland, deal, ungeregelt, burgerinn, referendum, unterhaus, may\n",
      "\n",
      "Topic: ' Grundgesetz/Demokratie '\n",
      "saudi, arabi, jem, rustungsexport, krieg, waff, iran, rustungsgut, humanitar, genehmigt, export, genehm, stopp, arab, konflikt, emirat, waffenliefer, bundessicherheitsrat, geliefert, waffenexport\n",
      "\n",
      "Topic: ' Syrienkonflikt/Naher Osten '\n",
      "rechtsstaat, recht, grundgesetz, forum, demokrati, justiz, karlsruh, artikel, gericht, grundrecht, verbraucherschutz, pakt, verfass, demokrat, freiheit, richt, bundesverfassungsgericht, stark, burg, leipzig\n",
      "\n",
      "Topic: ' Kosovoeinsatz '\n",
      "arzt, patient, arztinn, versorg, schwangerschaftsabbruch, information, patientinn, medizin, versichert, gesetz, spahn, informi, arztlich, schwang, werbung, hausarzt, krankenkass, termin, abtreib, gesundheitswes\n",
      "\n",
      "Topic: ' Nahostkonflikt '\n",
      "bafog, studier, studium, novell, student, reform, elt, erhoh, bericht, hochschul, gehring, studi, jung, gefordert, zahl, prozent, ministerin, ausbildungsforder, trendumkehr, freibetrag\n",
      "\n",
      "Topic: ' Innenpolitik/Rechtstaat '\n",
      "euro, milliard, million, jahr, prozent, geld, entlast, hoh, zahl, kost, erhoh, pro, rund, soli, dam, steuerzahl, zusatz, jahrlich, deutschland, griechenland\n",
      "\n",
      "Topic: ' Flüchtlingspolitik '\n",
      "israel, iran, libanon, unifil, abkomm, hisbollah, staat, region, libanes, judisch, atomabkomm, palastinens, antisemitismus, syri, existenzrecht, jud, nah, nation, amerikan, vereint\n",
      "\n",
      "Topic: ' Seenotrettung '\n",
      "afd, polit, dam, partei, geg, schon, deutschland, wied, imm, land, burg, cdu, demokrati, spd, regier, csu, jed, seit, selb, wahl\n",
      "\n",
      "Topic: ' Gesundheitspolitik '\n",
      "ost, ostdeutsch, ddr, west, ostdeutschland, jahr, mensch, einheit, damal, region, heut, bundesland, sed, thuring, treuhand, friedlich, lebensverhaltnis, revolution, wirtschaft, neu\n",
      "\n",
      "Topic: ' Afghanistaneinsatz '\n",
      "franzos, vertrag, frankreich, aach, zusammenarbeit, gemeinsam, freundschaft, élysé, parlament, macron, parlamentsabkomm, versamml, beid, zwisch, eng, parlamentar, deutschland, weltkrieg, bundestag, regier\n",
      "\n",
      "Topic: ' Brexit '\n",
      "digital, digitalisier, dat, intelligenz, kunstlich, infrastruktur, datenschutz, nutz, strategi, verkehr, burg, internet, netz, plattform, brauch, neu, zukunft, innovation, wandel, bereich\n",
      "\n",
      "Topic: ' Digitaliserung '\n",
      "turkei, syri, turkisch, erdogan, irak, nato, afrin, volkerrecht, volkerrechtswidr, syrisch, militar, kurd, russland, assad, geg, region, europarat, kurdisch, angriff, journalist\n",
      "\n",
      "Topic: ' Finanzmarktpolitik '\n",
      "fahrverbot, grenzwert, fahrzeug, stadt, luft, nachrust, saub, diesel, mobilitat, mikrogramm, scheu, verkehr, hardwarenachrust, automobilindustri, bahn, autos, auto, verkehrsminist, fahr, strass\n",
      "\n",
      "Topic: ' Malieinsatz '\n",
      "wolf, weidetierhalt, tier, population, schaf, erhaltungszustand, herdenschutz, jagdrecht, wolfspopulation, weideti, artenschutz, deutschland, mensch, entnahm, zaun, wolfsmanagement, abschuss, naturschutz, schutz, art\n",
      "\n",
      "Topic: ' Landwirtschaft '\n",
      "rent, rentenversicher, gesetz, grundrent, grundsicher, rentn, alt, altersarmut, prozent, selbststand, mutterrent, rentenniveau, heil, leistung, erwerbsminderungsrent, gearbeitet, lohn, beitrag, birkwald, rentnerinn\n"
     ]
    }
   ],
   "source": [
    "#display identified topics\n",
    "display_topics(nmf_35,tfidf_feature_names,20,topic_names = topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:35.160151Z",
     "start_time": "2019-10-14T23:27:34.849843Z"
    }
   },
   "outputs": [],
   "source": [
    "#create dataframe with topic values\n",
    "H_35 = pd.DataFrame(nmf_35_topic.round(5), columns = topic_names)\n",
    "\n",
    "#merge dataframes\n",
    "df = pd.concat([df.reset_index(drop=True), H_35.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Aggregation of speeches py parliament member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:20:28.530717Z",
     "start_time": "2019-09-24T04:20:28.527025Z"
    }
   },
   "source": [
    "## 7.1. Aggregation preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:35.232149Z",
     "start_time": "2019-10-14T23:27:35.164816Z"
    }
   },
   "outputs": [],
   "source": [
    "# get sum of topics per speech\n",
    "df['topic_sum']= 0\n",
    "for topic in topic_names:\n",
    "    df['topic_sum'] += df[topic]\n",
    "    \n",
    "#get percentage share of topic per speech\n",
    "aggregation_columns = topic_names + ['topic_sum']\n",
    "\n",
    "for topic in aggregation_columns:\n",
    "    df[topic] = df[topic]/df['topic_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:35.505438Z",
     "start_time": "2019-10-14T23:27:35.233994Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove speeches of non-parliament members\n",
    "df_parties = df[df['party']!='Other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Speech aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:35.818052Z",
     "start_time": "2019-10-14T23:27:35.507700Z"
    }
   },
   "outputs": [],
   "source": [
    "#sum word count and topic columns for each parliament member\n",
    "sum_columns = ['word_count'] + aggregation_columns\n",
    "\n",
    "df_speaker_parties = df_parties.groupby(['full_name','party'])[sum_columns].apply(lambda x: x.sum()).reset_index()\n",
    "\n",
    "#get percentage share of topic per parliament members\n",
    "for topic in topic_names:\n",
    "    df_speaker_parties[topic] = df_speaker_parties[topic]/df_speaker_parties['topic_sum']\n",
    "    \n",
    "df_speaker_parties.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:36:38.899631Z",
     "start_time": "2019-09-24T04:36:38.896271Z"
    }
   },
   "source": [
    "# 8. Cluster analysis (k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:35.969237Z",
     "start_time": "2019-10-14T23:27:35.820226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=15, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=44, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run cluster analysis\n",
    "km_15 = KMeans(n_clusters=15,random_state=44)\n",
    "\n",
    "X_speaker = df_speaker_parties[topic_names].values\n",
    "km_15.fit(X_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:36.050582Z",
     "start_time": "2019-10-14T23:27:35.972193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "Seenotrettung: 9.0%\n",
      "Innenpolitik/Rechtstaat: 8.0%\n",
      "Füllwörter: 6.0%\n",
      "Studium: 5.0%\n",
      "Parlamentsdebatten: 5.0%\n",
      "Gesundheitspolitik: 5.0%\n",
      "Bildungspolitik: 5.0%\n",
      "Familienpolitik: 3.0%\n",
      "\n",
      "\n",
      "Cluster 1\n",
      "Finanzmarktpolitik: 32.0%\n",
      "Brexit: 7.0%\n",
      "Seenotrettung: 6.0%\n",
      "Bundeswehr: 5.0%\n",
      "Innenpolitik/Rechtstaat: 5.0%\n",
      "Umwelt/Energie: 4.0%\n",
      "Parlamentsdebatten: 4.0%\n",
      "Wirtschaft: 4.0%\n",
      "\n",
      "\n",
      "Cluster 2\n",
      "Seenotrettung: 29.0%\n",
      "Bundeswehr: 6.0%\n",
      "Parlamentsdebatten: 5.0%\n",
      "Syrienkonflikt/Naher Osten: 5.0%\n",
      "Gesundheitspolitik: 4.0%\n",
      "Innenpolitik/Rechtstaat: 3.0%\n",
      "Parlamentsabstimmung: 3.0%\n",
      "Europa/EU-Politik: 3.0%\n",
      "\n",
      "\n",
      "Cluster 3\n",
      "Umwelt/Energie: 22.0%\n",
      "Seenotrettung: 8.0%\n",
      "Finanzmarktpolitik: 6.0%\n",
      "Parlamentsdebatten: 6.0%\n",
      "Bundeswehr: 5.0%\n",
      "Ländlicher Raum: 5.0%\n",
      "Europa/EU-Politik: 5.0%\n",
      "Wirtschaft: 4.0%\n",
      "\n",
      "\n",
      "Cluster 4\n",
      "Familienpolitik: 30.0%\n",
      "Seenotrettung: 7.0%\n",
      "Bundeswehr: 6.0%\n",
      "Parlamentsdebatten: 5.0%\n",
      "Innenpolitik/Rechtstaat: 5.0%\n",
      "Bildungspolitik: 4.0%\n",
      "Arbeitsmarkt: 4.0%\n",
      "Parlamentsabstimmung: 3.0%\n",
      "\n",
      "\n",
      "Cluster 5\n",
      "NATO/Sicherheitspolitik: 10.0%\n",
      "Digitaliserung: 10.0%\n",
      "Seenotrettung: 8.0%\n",
      "Flüchtlingspolitik: 8.0%\n",
      "Grundgesetz/Demokratie: 7.0%\n",
      "Europa/EU-Politik: 6.0%\n",
      "Haushalt: 6.0%\n",
      "Pflegepolitik: 5.0%\n",
      "\n",
      "\n",
      "Cluster 6\n",
      "Wirtschaft: 18.0%\n",
      "Seenotrettung: 7.0%\n",
      "Parlamentsdebatten: 6.0%\n",
      "Bundeswehr: 6.0%\n",
      "Innenpolitik/Rechtstaat: 6.0%\n",
      "Brexit: 5.0%\n",
      "Europa/EU-Politik: 5.0%\n",
      "Gesundheitspolitik: 3.0%\n",
      "\n",
      "\n",
      "Cluster 7\n",
      "Kosovoeinsatz: 20.0%\n",
      "Gesetzgebung: 12.0%\n",
      "Organspende: 9.0%\n",
      "Bundeswehr: 6.0%\n",
      "Seenotrettung: 6.0%\n",
      "Landwirtschaft: 4.0%\n",
      "Innenpolitik/Rechtstaat: 4.0%\n",
      "Parlamentsdebatten: 4.0%\n",
      "\n",
      "\n",
      "Cluster 8\n",
      "Haushalt: 23.0%\n",
      "Pflegepolitik: 15.0%\n",
      "Seenotrettung: 7.0%\n",
      "Sudaneinsatz: 5.0%\n",
      "Europa/EU-Politik: 5.0%\n",
      "Flüchtlingspolitik: 3.0%\n",
      "Parlamentsdebatten: 3.0%\n",
      "Parlamentsabstimmung: 3.0%\n",
      "\n",
      "\n",
      "Cluster 9\n",
      "Bundeswehr: 18.0%\n",
      "Seenotrettung: 12.0%\n",
      "Syrienkonflikt/Naher Osten: 9.0%\n",
      "Parlamentsdebatten: 6.0%\n",
      "Wirtschaft: 4.0%\n",
      "Bildungspolitik: 4.0%\n",
      "Europa/EU-Politik: 4.0%\n",
      "Arbeitsmarkt: 3.0%\n",
      "\n",
      "\n",
      "Cluster 10\n",
      "Ländlicher Raum: 30.0%\n",
      "Malieinsatz: 7.0%\n",
      "Seenotrettung: 5.0%\n",
      "Automobilverkehr: 4.0%\n",
      "Innenpolitik/Rechtstaat: 4.0%\n",
      "Bundeswehr: 4.0%\n",
      "Parlamentsdebatten: 3.0%\n",
      "Füllwörter: 3.0%\n",
      "\n",
      "\n",
      "Cluster 11\n",
      "Arbeitsmarkt: 21.0%\n",
      "Landwirtschaft: 16.0%\n",
      "Seenotrettung: 6.0%\n",
      "Bundeswehr: 6.0%\n",
      "Wirtschaft: 5.0%\n",
      "Parlamentsdebatten: 5.0%\n",
      "Innenpolitik/Rechtstaat: 5.0%\n",
      "Familienpolitik: 5.0%\n",
      "\n",
      "\n",
      "Cluster 12\n",
      "Europa/EU-Politik: 22.0%\n",
      "Seenotrettung: 8.0%\n",
      "Afghanistaneinsatz: 6.0%\n",
      "Förderalismus: 6.0%\n",
      "Parlamentsdebatten: 5.0%\n",
      "Füllwörter: 4.0%\n",
      "Digitaliserung: 4.0%\n",
      "Wirtschaft: 4.0%\n",
      "\n",
      "\n",
      "Cluster 13\n",
      "Miete/Wohnen: 24.0%\n",
      "Finanzmarktpolitik: 7.0%\n",
      "Seenotrettung: 6.0%\n",
      "Bildungspolitik: 6.0%\n",
      "Innenpolitik/Rechtstaat: 6.0%\n",
      "Bundeswehr: 5.0%\n",
      "Parlamentsdebatten: 5.0%\n",
      "Arbeitsmarkt: 4.0%\n",
      "\n",
      "\n",
      "Cluster 14\n",
      "Brexit: 33.0%\n",
      "Seenotrettung: 8.0%\n",
      "Wirtschaft: 7.0%\n",
      "Parlamentsdebatten: 6.0%\n",
      "Bundeswehr: 4.0%\n",
      "Europa/EU-Politik: 3.0%\n",
      "Parlamentsabstimmung: 3.0%\n",
      "Bildungspolitik: 3.0%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#explore cluster centers\n",
    "df_clusters_15 = pd.DataFrame(np.round(km_15.cluster_centers_,decimals=5),columns=topic_names)\n",
    "df_clusters_15\n",
    "\n",
    "for i in range(0,15):\n",
    "    cluster_values = df_clusters_15.iloc[i,:].values\n",
    "    top_3_idx = np.argsort(cluster_values)[::-1][:8]\n",
    "    top_3 = []\n",
    "    print ('Cluster {}'.format(i))\n",
    "    for i in top_3_idx:\n",
    "        print('{}: {}%'.format(topic_names[i],round(cluster_values[i]*100,0)))\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:36.060585Z",
     "start_time": "2019-10-14T23:27:36.053637Z"
    }
   },
   "outputs": [],
   "source": [
    "#name cluster based on topic distribution in centers\n",
    "cluster_dict = {0:'Sicherheitspolitik', 1:'Umwelt-/Energiepolitik',2:'Europapolitik',3:'Gesundheitspolitik',\n",
    "                4:'Arbeitsmarktpolitik',5:'Wirtschafts-/Finanzpolitik', 6:'Digitalisierung',7:'Demokratie/Rechtstaatlichkeit',\n",
    "                8:'Innen-/Justizpolitik',9:'Verkehr/Infrastruktur',10:'Familienpolitik', 11:'Außenpolitik',12:'Pflegepolitik',\n",
    "                13:'Bildungspolitik',14:'Landwirtschaftspolitik'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T23:27:36.089429Z",
     "start_time": "2019-10-14T23:27:36.072583Z"
    }
   },
   "outputs": [],
   "source": [
    "#add clusters to dataframe\n",
    "df_speaker_parties['cluster'] = km_15.labels_\n",
    "df_speaker_parties['cluster_name'] = df_speaker_parties['cluster'].map(cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
